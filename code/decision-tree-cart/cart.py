import numpy as np
from Node import Node
import pandas as pd

class DecisionTreeClassifier:
    def __init__(self, max_depth=None):
        self.max_depth = max_depth

    # Building decision tree classifier
    def fit(self,X,y):
        print("Building decision tree classifier")
        self.n_classes = len(set(y))
        self.n_features_ = X.shape[1]
        self.tree = self._grow_tree(X,y)

    def _grow_tree(self, X, y, depth = 0):
        print("grow treee")
        num_samples_per_class = [np.sum(y == i) for i in range(self.n_classes)]
        predicted_class = np.argmax(num_samples_per_class)
        node = Node(
            gini = self._gini(y),
            num_samples = y.size,
            num_samples_per_class = num_samples_per_class,
            predict_class=predicted_class,
        )
        # Split recursively until maximum depth is reached.
        if depth < self.max_depth:
            idx, thr = self._best_split(X, y)
            if idx is not None:
                print("IDX ",idx)
                indices_left = X[:, idx] < thr
                X_left, y_left = X[indices_left], y[indices_left]
                X_right, y_right = X[~indices_left], y[~indices_left]
                node.feature_index = idx
                node.threshold = thr
                node.left = self._grow_tree(X_left, y_left, depth + 1)
                node.right = self._grow_tree(X_right, y_right, depth + 1)
        return node

    # Predict class for X
    def predict(self, X):
        return np.array([self._predict(inputs) for inputs in X])

    # Predict class for a single sample
    def _predict(self, inputs):
        node = self.tree
        while node.left:
            if inputs[node.feature_index] < node.threshold:
                node = node.left
            else:
                node = node.right
        return node.predicted_class


    # Compute Gini impurity of a non-empty node
    # Gini impurity is defined as SUM p(1-p) over all classes, with p the frequency of a
    # class within the node. Since SUM p = 1, this is equivalent to 1 - SUM p^2.
    def _gini(self,y):
        m = y.size
        return 1 - sum((np.sum(y==c)/m)**2 for c in range(self.n_classes))



    """"
    To find the best split, we loop through all the features, and consider all the
    midpoints between adjacent training samples as possible thresholds. We compute
    the Gini impurity of the split generated by that particular feature/threshold
    pair, and return the pair with smallest impurity.
        
    Returns:
    best_idx: Index of the feature for best split, or None if no split is found.
    best_thr: Threshold to use for the split, or None if no split is found.
    """
    def _best_split(self, X, y):
        m = y.size
        # We need at least two elements to split a node
        if m <= 1:
            return None, None

        num_parent = [np.sum(y==c)for c in range(self.n_classes)]

        # Gini of current node
        best_gini = 1 - sum((n/m)** 2 for n in num_parent)
        best_idx, best_thr = None, None
        # iterate through features
        for idx in range(self.n_features_):
            if idx % 10 == 0:
                print("feature: #", idx, "/", self.n_features_)
            # Sortdata along selected feature
            # print(zip(X[:, idx], y))
            thresholds, classes = zip(*sorted(zip(X[:, idx], y)))

            num_left = [0] * self.n_classes
            num_right = num_parent.copy()
            for i in range(1,m):
                c = classes[i - 1]
                num_left[c] += 1
                num_right[c] -= 1

                gini_left = 1.0 - sum(
                    (num_right[x] / i)**2 for x in range(self.n_classes)
                )
                gini_right = 1 - sum(
                    (num_right[x] / (m-i) ** 2 for x in range(self.n_classes))
                )

                # The gini impurity is the avrage of the left and right gini
                gini = (i * gini_left + (m-i) * gini_right) / m

                if thresholds[i] == thresholds[i-1]:
                    continue

                if gini < best_gini:
                    best_gini = gini
                    best_idx = idx
                    best_thr = (thresholds[i] + thresholds[i-1]) / 2

        return best_idx, best_thr

if __name__ == "__main__":

    print("LOADING DATA")
    #load data
    train_data = pd.read_csv("../../input/train.csv").values
    test_data = pd.read_csv("../../input/test.csv").values
    print('Shape of training data :', train_data.shape)
    print('Shape of testing data :', test_data.shape)
    clf = DecisionTreeClassifier(max_depth=3)

    # Training dataset
    xTrain = train_data[0:, 1:]
    yTrain = train_data[0:, 0]
    clf.fit(xTrain, yTrain)

    # Predict value
    predtictY = clf.predict(test_data)

    # Create submission file
    df_sub = pd.DataFrame(list(range(1, len(test_data) + 1)))
    df_sub.columns = ["ImageID"]
    df_sub["Label"] = predtictY
    df_sub.to_csv("../../output/havlearn_LogRegr.csv", index=False)

